{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the OpenAI client\n",
    "from openai import OpenAI\n",
    "import json\n",
    "import dotenv\n",
    "import openai\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load credentials\n",
    "dotenv.load_dotenv('Credentials.env')\n",
    "\n",
    "# get api key\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# create the variable\n",
    "\n",
    "api_key=str(openai.api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the OpenAI client and set your API key\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(id='cmpl-9InbrqJ8v82JHQiqnZWR511Bxt7vm', choices=[CompletionChoice(finish_reason='length', index=0, logprobs=None, text='\\nChatGPT was developed by OpenAI, an artificial intelligence research organization based')], created=1714267631, model='gpt-3.5-turbo-instruct', object='text_completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=16, prompt_tokens=6, total_tokens=22))\n"
     ]
    }
   ],
   "source": [
    "# Create a request to the Completions endpoint\n",
    "response = client.completions.create(\n",
    "  # Specify the correct model\n",
    "  model=\"gpt-3.5-turbo-instruct\",\n",
    "  prompt=\"Who developed ChatGPT?\"\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Responses attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpt-3.5-turbo-instruct'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extract the model used from response using attributes.\n",
    "response.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionUsage(completion_tokens=16, prompt_tokens=6, total_tokens=22)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extract the total tokens used from response using attributes.\n",
    "\n",
    "response.usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ChatGPT was developed by OpenAI, an artificial intelligence research organization based\n"
     ]
    }
   ],
   "source": [
    "# Extract the text answer to the prompt from response.\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple ttasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholder cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace Taskts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\n",
      "A plane is an aircraft that is typically powered by jet engines or propellers\n"
     ]
    }
   ],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "prompt=\"\"\"Replace car with plane and adjust phrase:\n",
    "A car is a vehicle that is typically powered by an internal combustion engine or an electric motor. It has four wheels, and is designed to carry passengers and/or cargo on roads or highways. Cars have become a ubiquitous part of modern society, and are used for a wide variety of purposes, such as commuting, travel, and transportation of goods. Cars are often associated with freedom, independence, and mobility.\"\"\"\n",
    "\n",
    "# Create a request to the Completions endpoint\n",
    "response = client.completions.create(\n",
    "  model=\"gpt-3.5-turbo-instruct\",\n",
    "  prompt=prompt\n",
    ")\n",
    "\n",
    "# Extract and print the response text\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- Mexico's major cement producers predict modest growth in 2024 due to the completion of government infrastructure projects and budget reductions.\n",
      "- General construction activity in Mexico saw a 15.6% increase in 2023, driven by civil works, but growth expectations have cooled with the completion of major projects and anticipated budget cuts.\n",
      "- The National Cement Chamber forecasts a 2% rise in cement consumption in 2024, prompting cement producers to adjust\n"
     ]
    }
   ],
   "source": [
    "# Set API key\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "prompt=\"\"\"Summarize the following text into three concise bullet points:\n",
    "Mexico: Mexico's major cement producers predict modest growth in 2024 as some government infrastructure projects conclude and budget reductions take effect. These companies, including Cemex, Grupo Cementos and Holcim, have benefited from large-scale projects under President López Obrador but now face a tempered outlook.\n",
    "General construction activity in Mexico grew in 2023, with a 15.6% increase driven by civil works, increasing the construction industry's GDP to US$94bn. However, with the completion of projects like the Mayan Train and anticipated budget cuts, growth expectations have cooled.\n",
    "The National Cement Chamber forecasts a 2% rise in cement consumption in 2024, reaching 46.4Mt. Cement producers are adjusting strategies, with Cemex focusing on European markets and Holcim investing in plant expansions in Mexico, including a US$55m investment in its Macuspana plant in Tabasco.\n",
    "\"\"\"\n",
    "\n",
    "# Request\n",
    "response = client.completions.create(\n",
    "  model=\"gpt-3.5-turbo-instruct\",\n",
    "  prompt=prompt,\n",
    "  max_tokens=90,\n",
    "  temperature=0\n",
    "\n",
    ")\n",
    "\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\"Indulge in the flavors of Mazatlan at our table\"\n"
     ]
    }
   ],
   "source": [
    "# Set API key\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "prompt=\"\"\"Create an slogan for a new restaurant in Mazatlan\"\"\"\n",
    "\n",
    "# Request\n",
    "response = client.completions.create(\n",
    "  model=\"gpt-3.5-turbo-instruct\",\n",
    "  prompt=prompt,\n",
    "  max_tokens=90,\n",
    "  temperature=0\n",
    "\n",
    ")\n",
    "\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification tasks involve assigning a label to a piece of information. This can be identification, such as identifying the language used in a piece of text, categorization, such as sorting geographical locations into countries and US states, or even classifying a statement's sentiment, that is, whether it sounds positive or negative. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying text sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"classify the sentiment of the following statements as negative, positive, or neutral:\n",
    "Unbelievably good!\n",
    "Shoes fell apart on the second use.\n",
    "The shoes look nice, but they aren't very comfortable.\n",
    "Can't wait to show them off! \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Positive\n",
      "Negative\n",
      "Neutral\n",
      "Positive\n"
     ]
    }
   ],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Create a request to the Completions endpoint\n",
    "response = client.completions.create(\n",
    "  model=\"gpt-3.5-turbo-instruct\",\n",
    "  prompt=prompt,\n",
    "  max_tokens=90\n",
    ")\n",
    "\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorizing companies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=\"\"\"\n",
    " categorize the following companies: Apple, Microsoft, Saudi Aramco, Alphabet, Amazon, Berkshire Hathaway, NVIDIA, Meta, Tesla, and LVMH\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Technology/Electronics: Apple, Microsoft, Alphabet, Amazon, NVIDIA, Tesla\n",
      "2. Energy/Oil: Saudi Aramco\n",
      "3. Conglomerate: Berkshire Hathaway\n",
      "4. Social Media: Meta (formerly Facebook)\n",
      "5. Luxury Goods: LVMH\n"
     ]
    }
   ],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Create a request to the Completions endpoint\n",
    "response = client.completions.create(\n",
    "  model=\"gpt-3.5-turbo-instruct\",\n",
    "  prompt=prompt,\n",
    "  max_tokens=100,\n",
    "  temperature=0.5\n",
    ")\n",
    "\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=\"\"\"\n",
    " categorize the following companies: Apple, Microsoft, Saudi Aramco, Alphabet,Amazon, Berkshire Hathaway, NVIDIA, \n",
    " Meta, Tesla, and LVMH The four categories that the companies should be classified into are Tech, Energy, \n",
    " Luxury Goods, or Investment\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tech: Apple, Microsoft, Alphabet, Amazon, NVIDIA, Meta, Tesla\n",
      "Energy: Saudi Aramco\n",
      "Luxury Goods: LVMH\n",
      "Investment: Berkshire Hathaway\n"
     ]
    }
   ],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Create a request to the Completions endpoint\n",
    "response = client.completions.create(\n",
    "  model=\"gpt-3.5-turbo-instruct\",\n",
    "  prompt=prompt,\n",
    "  max_tokens=100,\n",
    "  temperature=0.5\n",
    ")\n",
    "\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat completions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Roles are at the heart of how chat models function. There are three main roles: the system, the user, and the assistant. \n",
    "- The system role allows the user to specify a message to control the behavior of the assistant. For example, for a customer service chatbot, we could provide a system message stating that the assistant is a polite and helpful customer service assistant. \n",
    "    * (Control assistant's behavior)\n",
    "- The user provides an instruction to the assistant, and\n",
    "    * Instruct the assitant\n",
    "- the assistant responds.\n",
    "    * Respond to the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In programming, both for loops and while loops are used for iteration, but they have some differences:\n",
      "\n",
      "1. For Loop:\n",
      "- A for loop is used when you know the number of iterations in advance.\n",
      "- It consists of an initialization, a condition, and an increment/decrement statement.\n",
      "- The loop control variable is updated automatically.\n",
      "- It is often used to iterate over a collection of elements like arrays or lists.\n",
      "\n",
      "Example of a for loop in Python:\n",
      "```python\n",
      "for i in range(5):\n",
      "    print(i)\n",
      "```\n",
      "\n",
      "2. While Loop:\n",
      "- A while loop is used when the number of iterations is not known in advance.\n",
      "- It only has a condition that is checked before each iteration.\n",
      "- The loop control variable must be\n"
     ]
    }
   ],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Create a request to the Chat Completions endpoint\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  max_tokens=100,\n",
    "  messages=[\n",
    "    {\"role\": \"system\",\n",
    "     \"content\": \"You are a helpful data science tutor.\"},\n",
    "    {\"role\":\"user\",\n",
    "    \"content\":\"What is the difference between a for loop and a while loop?\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "# Extract and print the assistant's text response\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Python code calculates and prints the mean height of the individuals listed in the 'heights_dict' dictionary using the numpy library.\n"
     ]
    }
   ],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=api_key)\n",
    "instruction = \"\"\"Explain what this Python code does in one sentence:\n",
    "import numpy as np\n",
    "\n",
    "heights_dict = {\"Mark\": 1.76, \"Steve\": 1.88, \"Adnan\": 1.73}\n",
    "heights = list(heights_dict.values())\n",
    "print(np.mean(heights))\n",
    "\"\"\"\n",
    "# Create a request to the Chat Completions endpoint\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  max_tokens=100,\n",
    "  messages=[\n",
    "    {\"role\": \"system\",\n",
    "     \"content\": \"You are a helpful Python programming assistant.\"},\n",
    "    {\"role\":\"user\",\n",
    "    \"content\":instruction}\n",
    "  ]\n",
    ")\n",
    "\n",
    "# Extract and print the assistant's text response\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In-context learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The type() function in Python is used to determine the type of an object. It returns the type of the object passed as an argument. For example, if you pass an integer to the type() function, it will return <class 'int'>. Similarly, if you pass a string, it will return <class 'str'>. This can be useful when you need to check the type of an object in your code or when you want to perform type checking.\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "response = client.chat.completions.create(\n",
    "   model=\"gpt-3.5-turbo\",\n",
    "   # Add a user and assistant message for in-context learning\n",
    "   messages=[\n",
    "     {\"role\": \"system\", \"content\": \"You are a helpful Python programming tutor.\"},\n",
    "     {\"role\":\"user\",\"content\":\"what it help() on python\"},\n",
    "     {\"role\": \"assistant\",\"content\":\"This give you an explication about modules\"},\n",
    "     {\"role\": \"user\", \"content\": \"Explain what the type() function does.\"}\n",
    "   ]\n",
    "   ,\n",
    "   max_tokens=100,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an AI chatbot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "messages = [{\"role\": \"system\", \"content\": \"You are a helpful math tutor.\"}]\n",
    "user_msgs = [\"Explain what pi is.\", \"Summarize this in two bullet points.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  Explain what pi is.\n",
      "Assistant:  Pi (π) is a mathematical constant representing the ratio of a circle's circumference to its diameter. It is approximately equal to 3.14159, but it is an irrational number, meaning it has an infinite number of non-repeating decimals. Pi is a fundamental constant in geometry and trigonometry and is used in various mathematical formulas and calculations involving circles and spheres. \n",
      "\n",
      "User:  Summarize this in two bullet points.\n",
      "Assistant:  - Pi (π) is a mathematical constant representing the ratio of a circle's circumference to its diameter.\n",
      "- It is an irrational number with an approximate value of 3.14159 and is commonly used in geometry and trigonometry calculations involving circles and spheres. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for q in user_msgs:\n",
    "    print(\"User: \", q)\n",
    "    \n",
    "    # Create a dictionary for the user message from q and append to messages\n",
    "    user_dict = {\"role\": \"user\", \"content\": q}\n",
    "    messages.append(user_dict)\n",
    "    \n",
    "    # Create the API request\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        max_tokens=100\n",
    "    )\n",
    "    \n",
    "    # Convert the assistant's message to a dict and append to messages\n",
    "    assistant_dict = {\"role\": \"assistant\", \"content\": response.choices[0].message.content}\n",
    "    messages.append(assistant_dict)\n",
    "    print(\"Assistant: \", response.choices[0].message.content, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beyoind text completions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text moderation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CategoryScores(harassment=1.3055409908702131e-05, harassment_threatening=7.816268407623284e-06, hate=4.331131640356034e-05, hate_threatening=1.6016556969589146e-07, self_harm=1.501566202932736e-06, self_harm_instructions=5.112408985041839e-07, self_harm_intent=4.494511927077838e-07, sexual=5.347801106836414e-06, sexual_minors=1.4448548881773604e-06, violence=0.001777988625690341, violence_graphic=4.5776912884321064e-05, self-harm=1.501566202932736e-06, sexual/minors=1.4448548881773604e-06, hate/threatening=1.6016556969589146e-07, violence/graphic=4.5776912884321064e-05, self-harm/intent=4.494511927077838e-07, self-harm/instructions=5.112408985041839e-07, harassment/threatening=7.816268407623284e-06)\n"
     ]
    }
   ],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Create a request to the Moderation endpoint\n",
    "response = client.moderations.create(\n",
    "  model=\"text-moderation-latest\",\n",
    "  input=\"My favorite book is How to Kill a Mockingbird.\"\n",
    ")\n",
    "\n",
    "# Get the category scores\n",
    "print(response.results[0].category_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript:\n",
      "Climate change is the greatest challenge our world faces\n",
      " As industry leaders\n",
      " we know that taking decisive climate action today is essential to building a sustainable world for tomorrow\n",
      " With today's population and urbanization trends\n",
      " our greatest challenge and our greatest opportunity is to build a net-zero future that works for people and the planet\n",
      " Concrete has shaped our modern world\n",
      " It will play a vital role in addressing the need for sustainable and prosperous communities through key infrastructure\n",
      " a home\n",
      " clean water and renewable energy\n",
      " and by providing a more resilient world as our climate changes\n",
      " In 2020\n",
      " our industry came together globally to commit to a 2050 climate ambition and align with global climate targets\n",
      " That ambition was to drive down the CO2 footprint of our operations and products and aspire to deliver society with carbon-neutral concrete by 2050\n",
      " Today\n",
      " we are announcing our concrete future\n",
      " the collective commitment and roadmap towards achieving a decarbonized industry and a net-zero concrete for the world\n",
      " The GCCA 2050 Cement and Concrete Industry Roadmap sets out the levers and milestones that will be required to achieve this goal\n",
      " It represents a decisive moment for our industry and the world\n",
      " showing an achievable net-zero route for the world's most used material after water\n",
      " It will require the industry to significantly accelerate the sustainability progress we have already achieved\n",
      " Over the last 30 years\n",
      " we have collectively reduced carbon dioxide emissions by 20% per ton of cementitious material\n",
      " And we are now setting out our commitment to a similar reduction by 2030 in just a third of the time on our way to achieving net-zero\n",
      " In this crucial next decade\n",
      " we are investing in our teams\n",
      " in new techniques and new technologies to achieve these reductions\n",
      " In our roadmap\n",
      " fossil fuel energy will be removed from the entire supply chain\n",
      " and more renewable energy and waste energy will be used\n",
      " New\n",
      " lower-carbon ingredients in cement and more efficient techniques will enable society to build more with less\n",
      " Innovations like carbon capture\n",
      " utilization and storage technologies\n",
      " which already has many life-pilot projects underway\n",
      " will move towards commercial-scale deployment\n",
      " Our net-zero commitment is a significant challenge and one we cannot achieve alone\n",
      " We need to work with all stakeholders in our value chain\n",
      " as well as with governments and policymakers\n",
      " to ensure the stage is set to make this possible\n",
      " Through our Concrete Future Roadmap\n",
      " we will deliver a decarbonized industry\n",
      " provide net-zero concrete and\n",
      " together\n",
      " build the sustainable world of tomorrow\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Api\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Open mp3\n",
    "audio_file = open(\"Concrete Future - The GCCA 2050 Cement and Concrete Industry Roadmap for Net Zero Concrete.mp3\", \"rb\")\n",
    "\n",
    "# Create a transcript\n",
    "response = client.audio.transcriptions.create(model=\"whisper-1\", file=audio_file)\n",
    "# Extract and print\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonjour, je m'appelle Maxime, j'ai 12 ans, j'aime beaucoup l'école. Je suis né en Colombie, mais j'habite en France. J'ai un frère et une sœur. Bon, à bientôt.\n"
     ]
    }
   ],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Open the audio.m4a file\n",
    "audio_file= open(\"How to instroduce yourself in french.mp3\", \"rb\")\n",
    "\n",
    "# Create a transcript from the audio file\n",
    "response = client.audio.transcriptions.create(model=\"whisper-1\", file=audio_file)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech translation ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Open the audio.m4a file\n",
    "audio_file = open(\"How to instroduce yourself in french.mp3\", \"rb\")\n",
    "\n",
    "# Create a translation from the audio file\n",
    "model_name = \"text-translation\"  # Default text translation model\n",
    "response = client.audio.translations.create(model=model_name, file=audio_file)\n",
    "\n",
    "# Extract and print the translated text\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The World Bank said in its latest economic outlook report that the global economy is in a dangerous state. As interest rates rise, consumer spending and corporate investment will slow down, economic activities will be impacted, and the vulnerability of low-income countries will be exposed. Global economic growth will be significantly slowed down, and the stability of the financial system will be threatened.\n"
     ]
    }
   ],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Open the audio.wav file\n",
    "audio_file = open(\"mandarin-full.wav\", \"rb\")\n",
    "\n",
    "# Write an appropriate prompt to help the model\n",
    "prompt = \"The transcript contains a discussion on a recent World Bank Report.\"\n",
    "\n",
    "# Create a translation from the audio file\n",
    "response = client.audio.translations.create(model=\"whisper-1\",\n",
    "                                            file=audio_file,\n",
    "                                            prompt=prompt)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying audio language tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text is written in German.\n"
     ]
    }
   ],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Open the audio.wav file\n",
    "audio_file = open(\"arne-german-automotive-forecast.wav\", \"rb\")\n",
    "\n",
    "# Create a transcription request using audio_file\n",
    "audio_response = client.audio.transcriptions.create(model=\"whisper-1\", file=audio_file)\n",
    "\n",
    "# Create a request to the API to identify the language spoken\n",
    "chat_response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a languages specialist.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Identify the language used in the following text: \" + audio_response.text}\n",
    "  ]\n",
    ")\n",
    "print(chat_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The story of the fox and the crow is a fable that teaches a valuable lesson about deception and trust. In the story, the fox uses flattery to deceive the crow and steal the cheese. The crow's vanity leads him to be tricked by the fox's words and lose what he had. However, the crow eventually realizes that the loss of trust is more significant than the loss of material possessions.\n",
      "\n",
      "The real meaning behind this story is that we should be cautious of flattery and not let\n"
     ]
    }
   ],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Open the datacamp-q2-roadmap.mp3 file\n",
    "audio_file = open(\"The fox and the crow.mp3\", \"rb\")\n",
    "\n",
    "# Create a transcription request using audio_file\n",
    "audio_response = client.audio.transcriptions.create(model=\"whisper-1\", file=audio_file)\n",
    "\n",
    "# Create a request to the API to summarize the transcript into bullet points\n",
    "chat_response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful teacher.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Explain the story and the real meaning\" + audio_response.text}\n",
    "  ],\n",
    "  max_tokens=100\n",
    ")\n",
    "print(chat_response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
