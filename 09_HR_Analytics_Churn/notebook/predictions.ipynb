{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19e21412",
   "metadata": {},
   "source": [
    "# HR Analytics: Predicting Employee Churn\n",
    "\n",
    "Understanding why employees leave and building a model to predict turnover.\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "Employee turnover is costly. This analysis aims to:\n",
    "1. Understand factors driving employee churn\n",
    "2. Build a predictive model to identify at-risk employees\n",
    "3. Provide actionable insights for HR teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0b4ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84780713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df = pd.read_csv('../data/turnover.csv')\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68929a90",
   "metadata": {},
   "source": [
    "## Data Overview\n",
    "\n",
    "Let's check the structure and quality of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b19d0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic info\n",
    "print(\"Data types:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nMissing values:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\nBasic statistics:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445c61a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# churn distribution\n",
    "print(f\"Churn rate: {df['churn'].mean()*100:.1f}%\")\n",
    "df['churn'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3648c8",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "### Satisfaction vs Churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bd61b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# satisfaction distribution by churn status\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# satisfaction histogram\n",
    "axes[0].hist(df[df['churn']==0]['satisfaction'], bins=20, alpha=0.7, label='Stayed')\n",
    "axes[0].hist(df[df['churn']==1]['satisfaction'], bins=20, alpha=0.7, label='Left')\n",
    "axes[0].set_xlabel('Satisfaction Level')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('Satisfaction Distribution')\n",
    "axes[0].legend()\n",
    "\n",
    "# evaluation histogram\n",
    "axes[1].hist(df[df['churn']==0]['evaluation'], bins=20, alpha=0.7, label='Stayed')\n",
    "axes[1].hist(df[df['churn']==1]['evaluation'], bins=20, alpha=0.7, label='Left')\n",
    "axes[1].set_xlabel('Last Evaluation')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_title('Evaluation Distribution')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abf4b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# churn by department\n",
    "dept_churn = df.groupby('department')['churn'].mean().sort_values(ascending=False)\n",
    "plt.figure(figsize=(10, 5))\n",
    "dept_churn.plot(kind='bar', color='steelblue')\n",
    "plt.title('Churn Rate by Department')\n",
    "plt.xlabel('Department')\n",
    "plt.ylabel('Churn Rate')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32bb8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# churn by salary level\n",
    "salary_churn = df.groupby('salary')['churn'].mean()\n",
    "print(\"Churn rate by salary:\")\n",
    "print(salary_churn)\n",
    "\n",
    "# churn by number of projects\n",
    "project_churn = df.groupby('number_of_projects')['churn'].mean()\n",
    "plt.figure(figsize=(8, 4))\n",
    "project_churn.plot(kind='bar', color='coral')\n",
    "plt.title('Churn Rate by Number of Projects')\n",
    "plt.xlabel('Number of Projects')\n",
    "plt.ylabel('Churn Rate')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9470f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation heatmap for numeric features\n",
    "numeric_cols = ['satisfaction', 'evaluation', 'number_of_projects', \n",
    "                'average_montly_hours', 'time_spend_company', 'work_accident', \n",
    "                'churn', 'promotion']\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(df[numeric_cols].corr(), annot=True, cmap='RdBu_r', center=0)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd431746",
   "metadata": {},
   "source": [
    "## Feature Engineering & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932c7db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode categorical variables\n",
    "df_encoded = df.copy()\n",
    "\n",
    "# salary encoding (ordinal)\n",
    "salary_map = {'low': 0, 'medium': 1, 'high': 2}\n",
    "df_encoded['salary'] = df_encoded['salary'].map(salary_map)\n",
    "\n",
    "# department encoding (one-hot)\n",
    "df_encoded = pd.get_dummies(df_encoded, columns=['department'], drop_first=True)\n",
    "\n",
    "print(f\"Features after encoding: {df_encoded.shape[1]}\")\n",
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97761bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare features and target\n",
    "X = df_encoded.drop('churn', axis=1)\n",
    "y = df_encoded['churn']\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cbd866",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532a0043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression\n",
    "lr = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "lr_pred = lr.predict(X_test)\n",
    "\n",
    "print(\"Logistic Regression Results:\")\n",
    "print(classification_report(y_test, lr_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5198c71e",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995bfb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"Random Forest Results:\")\n",
    "print(classification_report(y_test, rf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb536f2",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec1f5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrices\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# logistic regression cm\n",
    "cm_lr = confusion_matrix(y_test, lr_pred)\n",
    "sns.heatmap(cm_lr, annot=True, fmt='d', cmap='Blues', ax=axes[0])\n",
    "axes[0].set_title('Logistic Regression')\n",
    "axes[0].set_xlabel('Predicted')\n",
    "axes[0].set_ylabel('Actual')\n",
    "\n",
    "# random forest cm\n",
    "cm_rf = confusion_matrix(y_test, rf_pred)\n",
    "sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Greens', ax=axes[1])\n",
    "axes[1].set_title('Random Forest')\n",
    "axes[1].set_xlabel('Predicted')\n",
    "axes[1].set_ylabel('Actual')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8d63bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curves\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# logistic regression ROC\n",
    "lr_proba = lr.predict_proba(X_test)[:, 1]\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_test, lr_proba)\n",
    "roc_auc_lr = auc(fpr_lr, tpr_lr)\n",
    "ax.plot(fpr_lr, tpr_lr, label=f'Logistic Regression (AUC = {roc_auc_lr:.3f})')\n",
    "\n",
    "# random forest ROC\n",
    "rf_proba = rf.predict_proba(X_test)[:, 1]\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, rf_proba)\n",
    "roc_auc_rf = auc(fpr_rf, tpr_rf)\n",
    "ax.plot(fpr_rf, tpr_rf, label=f'Random Forest (AUC = {roc_auc_rf:.3f})')\n",
    "\n",
    "# diagonal line\n",
    "ax.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
    "\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title('ROC Curves')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb4a89b",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830f3015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature importance from random forest\n",
    "feature_imp = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': rf.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_imp['feature'][:10], feature_imp['importance'][:10])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Top 10 Feature Importances (Random Forest)')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 5 features:\")\n",
    "print(feature_imp.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23eb99b",
   "metadata": {},
   "source": [
    "## Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395a99e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation scores\n",
    "cv_lr = cross_val_score(lr, X, y, cv=5, scoring='accuracy')\n",
    "cv_rf = cross_val_score(rf, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "print(\"5-Fold Cross-Validation Accuracy:\")\n",
    "print(f\"Logistic Regression: {cv_lr.mean():.4f} (+/- {cv_lr.std()*2:.4f})\")\n",
    "print(f\"Random Forest:       {cv_rf.mean():.4f} (+/- {cv_rf.std()*2:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac96d47",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "1. **Satisfaction is the strongest predictor** - Employees with low satisfaction scores are much more likely to leave\n",
    "\n",
    "2. **Workload matters** - Both too few projects (2) and too many (6-7) increase churn risk\n",
    "\n",
    "3. **Time at company** - Employees with 3-5 years tenure show higher churn, possibly due to career advancement expectations\n",
    "\n",
    "4. **Low salary = higher risk** - Clear correlation between salary level and retention\n",
    "\n",
    "### Model Performance\n",
    "\n",
    "- Random Forest outperforms Logistic Regression with higher AUC\n",
    "- The model can identify at-risk employees with good precision\n",
    "\n",
    "### Recommendations for HR\n",
    "\n",
    "1. Monitor satisfaction scores regularly\n",
    "2. Balance project assignments (3-5 projects seems optimal)\n",
    "3. Review compensation for long-tenured employees\n",
    "4. Consider career development programs for 3-5 year employees"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
