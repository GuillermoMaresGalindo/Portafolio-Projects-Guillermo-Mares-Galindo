# Introduction to PySpark

Learning Apache Spark with Python for big data processing.

## Topics Covered

- SparkSession creation
- Loading data into DataFrames
- Basic transformations (select, filter, withColumn)
- Aggregations (groupBy, agg)
- SQL queries with Spark
- Data analysis patterns

## Dataset

Data science salaries dataset with job titles, experience levels, and compensation.

## When to Use Spark

- Data doesn't fit in memory
- Need distributed processing
- Working with data lakes
- ETL pipelines at scale

## Running

Requires PySpark installed:
```bash
pip install pyspark
```

## Files

- `introduction.ipynb` - Main tutorial notebook
- `Data/salaries.csv` - Sample dataset
